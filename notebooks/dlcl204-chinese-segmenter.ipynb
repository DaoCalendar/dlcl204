{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern Chinese segmenter\n",
    "\n",
    "This Jupyter notebook takes a text file, or folder of text files in Chinese, and creates a set of segmented derivative files (where all words are separated by spaces). These segmented files can then be used for searching, or other computational text analysis methods.\n",
    "\n",
    "Please only use this for **modern** Chinese. Classical Chinese works better with per-character segmenting (putting a space in between each character)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-time setup\n",
    "The first code cell below installs the [*jieba* package](https://github.com/fxsjy/jieba) which can do the actual segmentingg. You only need to run it the first time you use this notebook in a particular environment (laptop, virtual machine, etc.) You can skip it the next time you use the notebook, but nothing bad will happen if you re-run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports the sys module which you can use to perform system-level things \n",
    "#like installing new modules\n",
    "import sys\n",
    "\n",
    "#Installs jieba\n",
    "!{sys.executable} -m pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules\n",
    "\n",
    "The next code cell imports the modules you need to run this notebook. Run it every time you open this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os is used for navigating your filesystem and getting to the files you want to lemmatize\n",
    "import os\n",
    "\n",
    "#jieba is the module that does the actual lemmatizing\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing a single file\n",
    "Put the full path to your text file in the cell below, using the correct syntax for your operating system. \n",
    "\n",
    "For instance, the default path a text file in the Documents directory is (substituting your user name on the computer for YOUR-USER-NAME):\n",
    "\n",
    "* On Mac: '/Users/YOUR-USER-NAME/Documents/YOUR-TEXT-FILE.txt'\n",
    "* On Windows: 'C:\\\\Users\\\\YOUR-USER-NAME\\\\Documents\\\\YOUR-TEXT-FILE.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the full path to your file between the single quotes here\n",
    "filepath = '/Users/qad/Documents/chinese.txt'\n",
    "\n",
    "#The outname is the name of the lemmatized file that this notebook creates\n",
    "#If you want it to be named something other than the original file name + -segmented\n",
    "#you can change that here\n",
    "outname = filepath.replace('.txt', '-segmented.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens the file you specified\n",
    "with open(filepath, 'r') as f:\n",
    "    #Creates an empty text file with -segmented.txt appended to the name\n",
    "    with open(outname, 'w') as out:\n",
    "        #Reads the text of the file you specified\n",
    "        text = f.read()\n",
    "        #Segments the text\n",
    "        tokens = jieba.cut(text)\n",
    "        #Combine the tokens\n",
    "        segmented = \" \".join(tokens)\n",
    "        #Writes the lemmas to the text file with -segmented appended to the name\n",
    "        out.write(segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing a folder of text files\n",
    "Put the full path to your folder of text files in the cell below, using the correct syntax for your operating system. \n",
    "\n",
    "For instance, the default path to a folder called \"chinese\" in the Documents directory is (substituting your user name on the computer for YOUR-USER-NAME):\n",
    "\n",
    "* On Mac: '/Users/YOUR-USER-NAME/Documents/chinese'\n",
    "* On Windows: 'C:\\\\Users\\\\YOUR-USER-NAME\\\\Documents\\\\chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the full path to your folder between single quotes here\n",
    "textfolder = '/Users/qad/Documents/chinese'\n",
    "#Changes the working directory to the folder you specified\n",
    "os.chdir(textfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For every file in the folder you specified...\n",
    "for filename in os.listdir(textfolder):\n",
    "    #If it's a text file, but not one of the text files with just lemmas\n",
    "    if filename.endswith('.txt') and not filename.endswith('-segmented.txt'):\n",
    "        #The outname is the name of the lemmatized file that this notebook creates\n",
    "        #If you want it to be named something other than the original file name + -lemmatized\n",
    "        #you can change that here\n",
    "        outname = filename.replace('.txt', '-segmented.txt')\n",
    "        #Opens the file you specified\n",
    "        with open(filename, 'r') as f:\n",
    "            #Creates an empty text file with -lemmatized.txt appended to the name\n",
    "            with open(outname, 'w') as out:\n",
    "                #Reads the text of the file you specified\n",
    "                text = f.read()\n",
    "                #Segments the text\n",
    "                tokens = jieba.cut(text)\n",
    "                #Combine the tokens\n",
    "                segmented = \" \".join(tokens)\n",
    "                #Writes the lemmas to the text file with -segmented appended to the name\n",
    "                out.write(segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "This Jupyter notebook was originally developed by Quinn Dombrowski for use in [DLCL 204: Digital Humanities Across Borders](https://github.com/quinnanya/dlcl204) at Stanford University, fall 2020. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
